{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1OQCC1Fi9v_IA9EtiGmHL25XZIspDyQNT","authorship_tag":"ABX9TyMkYlM1seQIfwc71jqR8tAY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"neBXiOdd2K6a","executionInfo":{"status":"ok","timestamp":1674150672311,"user_tz":-330,"elapsed":5191,"user":{"displayName":"ABDUL HAQUE","userId":"03599932539934700066"}},"outputId":"b9ed6feb-8bf5-46d5-8dfc-ce7fc41d89bc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: gdown in /usr/local/lib/python3.8/dist-packages (4.6.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from gdown) (4.64.1)\n","Requirement already satisfied: requests[socks] in /usr/local/lib/python3.8/dist-packages (from gdown) (2.25.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from gdown) (3.9.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from gdown) (4.6.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from gdown) (1.15.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2.10)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (4.0.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.24.3)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.7.1)\n"]}],"source":["# pip install --upgrade --no-cache-dir gdown"]},{"cell_type":"code","source":["!gdown --id 1diztKyKFfhINpY-8R_KB84kV8akW2NjD"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DihTw_kZ2UWQ","executionInfo":{"status":"ok","timestamp":1674150688607,"user_tz":-330,"elapsed":6358,"user":{"displayName":"ABDUL HAQUE","userId":"03599932539934700066"}},"outputId":"59fc48b2-968f-4619-f511-fbb3ddf4fd5a"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.8/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n","  warnings.warn(\n","Downloading...\n","From: https://drive.google.com/uc?id=1diztKyKFfhINpY-8R_KB84kV8akW2NjD\n","To: /content/test_train_val.zip\n","100% 480M/480M [00:03<00:00, 158MB/s]\n"]}]},{"cell_type":"code","source":["!unzip -qq test_train_val.zip"],"metadata":{"id":"kEQD7Ft62kAg","executionInfo":{"status":"ok","timestamp":1674150699271,"user_tz":-330,"elapsed":7572,"user":{"displayName":"ABDUL HAQUE","userId":"03599932539934700066"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7e8fdd59-99bd-4939-e009-e43c091ebfef"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["replace test_train_val/test_meta.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.metrics import roc_auc_score, log_loss\n","from sklearn import metrics\n","from sklearn.preprocessing import LabelEncoder, MinMaxScaler"],"metadata":{"id":"yNf01W2c2uTL","executionInfo":{"status":"ok","timestamp":1674150704765,"user_tz":-330,"elapsed":2809,"user":{"displayName":"ABDUL HAQUE","userId":"03599932539934700066"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["with open('test_train_val/train_meta.csv') as f:\n","  train_df= pd.read_csv(f)\n","with open('test_train_val/train_signal.csv') as f:\n","  train_signal = pd.read_csv(f)\n","\n","with open('test_train_val/valid_meta.csv') as f:\n","  valid_df= pd.read_csv(f)\n","with open('test_train_val/valid_signal.csv') as f:\n","  valid_signal = pd.read_csv(f)\n","\n","with open('test_train_val/test_meta.csv') as f:\n","  test_df= pd.read_csv(f)\n","with open('test_train_val/test_signal.csv') as f:\n","  test_signal = pd.read_csv(f)\n","\n","print(train_df.shape)\n","\n","train_df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":678},"id":"tzkYCN5L3E_4","executionInfo":{"status":"ok","timestamp":1674150732566,"user_tz":-330,"elapsed":25022,"user":{"displayName":"ABDUL HAQUE","userId":"03599932539934700066"}},"outputId":"524a79e1-21bc-4ac1-91a7-6fa8eb6d32ba"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["(17441, 37)\n"]},{"output_type":"execute_result","data":{"text/plain":["       ecg_id   age  sex  height  weight  nurse  site      device  NORM  MI  \\\n","0           1  56.0    1     NaN    63.0    2.0   0.0   CS-12   E     1   0   \n","1           2  19.0    0     NaN    70.0    2.0   0.0   CS-12   E     1   0   \n","2           3  37.0    1     NaN    69.0    2.0   0.0   CS-12   E     1   0   \n","3           4  24.0    0     NaN    82.0    2.0   0.0   CS-12   E     1   0   \n","4           5  19.0    1     NaN    70.0    2.0   0.0   CS-12   E     1   0   \n","...       ...   ...  ...     ...     ...    ...   ...         ...   ...  ..   \n","17436   21832  63.0    0     NaN     NaN    1.0   2.0  AT-60    3     0   0   \n","17437   21833  67.0    1     NaN     NaN    1.0   2.0  AT-60    3     0   0   \n","17438   21834  93.0    0     NaN     NaN    1.0   2.0  AT-60    3     1   0   \n","17439   21835  59.0    1     NaN     NaN    1.0   2.0  AT-60    3     0   0   \n","17440   21836  64.0    1     NaN     NaN    1.0   2.0  AT-60    3     1   0   \n","\n","       ...  sub_ISC_  sub_SEHYP  sub_ISCI  sub_CRBBB  sub_CLBBB  sub_LAO/LAE  \\\n","0      ...         0          0         0          0          0            0   \n","1      ...         0          0         0          0          0            0   \n","2      ...         0          0         0          0          0            0   \n","3      ...         0          0         0          0          0            0   \n","4      ...         0          0         0          0          0            0   \n","...    ...       ...        ...       ...        ...        ...          ...   \n","17436  ...         0          0         0          0          0            0   \n","17437  ...         0          0         0          0          0            0   \n","17438  ...         0          0         0          0          0            0   \n","17439  ...         0          0         0          0          0            0   \n","17440  ...         0          0         0          0          0            0   \n","\n","       sub_ILBBB  sub_WPW  sub_PMI  strat_fold  \n","0              0        0        0           3  \n","1              0        0        0           2  \n","2              0        0        0           5  \n","3              0        0        0           3  \n","4              0        0        0           4  \n","...          ...      ...      ...         ...  \n","17436          0        0        0           7  \n","17437          0        0        0           7  \n","17438          0        0        0           4  \n","17439          0        0        0           2  \n","17440          0        0        0           8  \n","\n","[17441 rows x 37 columns]"],"text/html":["\n","  <div id=\"df-afebd206-17be-469a-90c8-be6186eea2eb\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ecg_id</th>\n","      <th>age</th>\n","      <th>sex</th>\n","      <th>height</th>\n","      <th>weight</th>\n","      <th>nurse</th>\n","      <th>site</th>\n","      <th>device</th>\n","      <th>NORM</th>\n","      <th>MI</th>\n","      <th>...</th>\n","      <th>sub_ISC_</th>\n","      <th>sub_SEHYP</th>\n","      <th>sub_ISCI</th>\n","      <th>sub_CRBBB</th>\n","      <th>sub_CLBBB</th>\n","      <th>sub_LAO/LAE</th>\n","      <th>sub_ILBBB</th>\n","      <th>sub_WPW</th>\n","      <th>sub_PMI</th>\n","      <th>strat_fold</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>56.0</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>63.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>CS-12   E</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>19.0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>70.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>CS-12   E</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>37.0</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>69.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>CS-12   E</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>24.0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>82.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>CS-12   E</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>19.0</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>70.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>CS-12   E</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>17436</th>\n","      <td>21832</td>\n","      <td>63.0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>AT-60    3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>17437</th>\n","      <td>21833</td>\n","      <td>67.0</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>AT-60    3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>17438</th>\n","      <td>21834</td>\n","      <td>93.0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>AT-60    3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>17439</th>\n","      <td>21835</td>\n","      <td>59.0</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>AT-60    3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>17440</th>\n","      <td>21836</td>\n","      <td>64.0</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>AT-60    3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>8</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>17441 rows × 37 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-afebd206-17be-469a-90c8-be6186eea2eb')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-afebd206-17be-469a-90c8-be6186eea2eb button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-afebd206-17be-469a-90c8-be6186eea2eb');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["class PTBXLDatasetPreprocesser():\n","    def __init__(self):\n","        pass\n","    \n","    def save(self, filename):\n","        data = {\n","            'superclass_cols': self.superclass_cols,\n","            'subclass_cols': self.subclass_cols,\n","            'meta_num_cols': self.meta_num_cols,\n","            'meta_num_means': self.meta_num_means,\n","            'min_max_scaler': self.min_max_scaler,\n","            'meta_cat_cols': self.meta_cat_cols,\n","            'cat_lablers': self.cat_lablers,\n","            'bclass_cols': self.bclass_cols,\n","            \n","        }\n","        pd.to_pickle(data, filename)\n","        \n","    def load(self, filename):\n","        data = pd.read_pickle(filename)\n","        self.min_max_scaler = data['min_max_scaler']\n","        self.cat_lablers = data['cat_lablers']\n","        #self.binary_lablers = data['binary_lablers']\n","        \n","    def fit(self, x, y):\n","        x = x.copy()\n","        y = y.copy()\n","        \n","        self.superclass_cols = [ 'MI', 'STTC', 'CD', 'HYP']\n","        \n","        self.subclass_cols = [col for col in y.columns if 'sub_' in col]\n","\n","        self.bclass_cols = ['NORM']\n","        \n","        self.meta_num_cols = ['age', 'height', 'weight']\n","        self.meta_num_means = []\n","        for col in self.meta_num_cols:\n","            print(col, y[col].mean())\n","            y[col] = y[col].fillna(y[col].mean())\n","            self.meta_num_means += [y[col].mean()]\n","            \n","        self.min_max_scaler = MinMaxScaler().fit(y[self.meta_num_cols])\n","        \n","        self.meta_cat_cols = ['sex'] #, 'nurse', 'device']\n","        self.cat_lablers = [LabelEncoder().fit(y[col].fillna('none').astype(str)) for col in self.meta_cat_cols]\n","        return self\n","\n","        #self.min_max_scaler = MinMaxScaler().fit(y[self.meta_num_cols])\n","        \n","        #self.meta_binary_cols = ['NORM'] \n","        #self.binary_lablers = [LabelEncoder().fit(y[col].fillna('none').astype(str)) for col in self.meta_binary_cols]\n","        #return self\n","    \n","    def transform(self, x, y):\n","        \n","        channel_cols = x.columns.tolist()[1:]\n","        \n","        ret = []\n","        x = x[channel_cols].values.reshape(-1, 1000, 12)\n","        print(x.shape)\n","        ret += [x] # signal\n","        \n","        y_ = y.copy()\n","        \n","        for i, col in enumerate(self.meta_num_cols):\n","            y_[col] = y_[col].fillna(self.meta_num_means[i])\n","        y_[self.meta_num_cols] = self.min_max_scaler.transform(y_[self.meta_num_cols])\n","        y_[self.meta_num_cols] = np.clip(y_[self.meta_num_cols], 0., 1.) # prevent extreme value far from train set\n","        \n","        ret += [y_[self.meta_num_cols]] # meta num features\n","        \n","        for i, col in enumerate(self.meta_cat_cols):\n","            y_[col] = y_[col].fillna('none').astype(str)\n","            y_[col] = self.cat_lablers[i].transform(y_[col]) \n","        \n","        ret += [y_[self.meta_cat_cols]] # meta cat features\n","\n","        #for i, col in enumerate(self.meta_binary_cols):\n","           # y_[col] = y_[col].fillna('none').astype(str)\n","           # y_[col] = self.binary_lablers[i].transform(y_[col]) \n","        \n","        #ret += [y_[self.meta_binary_cols]] # binary class target\n","        \n","        if np.isin(self.superclass_cols, y.columns).sum() == len(self.superclass_cols):\n","            ret += [y[self.superclass_cols].fillna(0).astype(int)] # superclass targets\n","        \n","        if np.isin(self.subclass_cols, y.columns).sum() == len(self.subclass_cols):\n","            ret += [y[self.subclass_cols].fillna(0).astype(int)] # subclass targets\n","\n","        if np.isin(self.bclass_cols, y.columns).sum() == len(self.bclass_cols):\n","            ret += [y[self.bclass_cols].fillna(0).astype(int)]\n","        \n","        return ret"],"metadata":{"id":"dw6y28jO3Hz_","executionInfo":{"status":"ok","timestamp":1674150734900,"user_tz":-330,"elapsed":2,"user":{"displayName":"ABDUL HAQUE","userId":"03599932539934700066"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["data_preprocessor = PTBXLDatasetPreprocesser()\n","data_preprocessor.fit(train_signal, train_df)\n","train_signal, train_meta_num_feats, train_meta_cat_feats, train_superclass, train_subclass, train_bclass = data_preprocessor.transform(train_signal, train_df)\n","valid_signal, valid_meta_num_feats, valid_meta_cat_feats, valid_superclass, valid_subclass, valid_bclass = data_preprocessor.transform(valid_signal, valid_df)\n","test_signal, test_meta_num_feats, test_meta_cat_feats, test_superclass, test_subclass, test_bclass = data_preprocessor.transform(test_signal, test_df)\n","\n","print(train_signal.shape)\n","print(valid_meta_num_feats.isna().sum(), valid_meta_cat_feats.isna().sum(), valid_superclass.isna().sum(), valid_subclass.isna().sum(), valid_bclass.isna().sum())\n","\n","display(train_meta_num_feats)\n","display(train_meta_cat_feats)\n","display(train_superclass)\n","display(train_subclass)\n","display(train_bclass)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"-3-Yy0xS3Sha","executionInfo":{"status":"ok","timestamp":1674150739175,"user_tz":-330,"elapsed":1958,"user":{"displayName":"ABDUL HAQUE","userId":"03599932539934700066"}},"outputId":"5df6c26f-070c-43a4-e735-e353515fac75"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["age 59.63709074169975\n","height 166.68908469699693\n","weight 70.69599447513812\n","(17441, 1000, 12)\n","(2193, 1000, 12)\n","(2203, 1000, 12)\n","(17441, 1000, 12)\n","age       0\n","height    0\n","weight    0\n","dtype: int64 sex    0\n","dtype: int64 MI      0\n","STTC    0\n","CD      0\n","HYP     0\n","dtype: int64 sub_NORM         0\n","sub_IMI          0\n","sub_STTC         0\n","sub_NST_         0\n","sub_LVH          0\n","sub_LAFB/LPFB    0\n","sub_RVH          0\n","sub_RAO/RAE      0\n","sub_IRBBB        0\n","sub_IVCD         0\n","sub_LMI          0\n","sub_AMI          0\n","sub__AVB         0\n","sub_ISCA         0\n","sub_ISC_         0\n","sub_SEHYP        0\n","sub_ISCI         0\n","sub_CRBBB        0\n","sub_CLBBB        0\n","sub_LAO/LAE      0\n","sub_ILBBB        0\n","sub_WPW          0\n","sub_PMI          0\n","dtype: int64 NORM    0\n","dtype: int64\n"]},{"output_type":"display_data","data":{"text/plain":["            age    height    weight\n","0      0.580645  0.791572  0.282927\n","1      0.182796  0.791572  0.317073\n","2      0.376344  0.791572  0.312195\n","3      0.236559  0.791572  0.375610\n","4      0.182796  0.791572  0.317073\n","...         ...       ...       ...\n","17436  0.655914  0.791572  0.320468\n","17437  0.698925  0.791572  0.320468\n","17438  0.978495  0.791572  0.320468\n","17439  0.612903  0.791572  0.320468\n","17440  0.666667  0.791572  0.320468\n","\n","[17441 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-4a97b0b9-b00a-4c9f-93e1-31fa0c2fc019\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>height</th>\n","      <th>weight</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.580645</td>\n","      <td>0.791572</td>\n","      <td>0.282927</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.182796</td>\n","      <td>0.791572</td>\n","      <td>0.317073</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.376344</td>\n","      <td>0.791572</td>\n","      <td>0.312195</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.236559</td>\n","      <td>0.791572</td>\n","      <td>0.375610</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.182796</td>\n","      <td>0.791572</td>\n","      <td>0.317073</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>17436</th>\n","      <td>0.655914</td>\n","      <td>0.791572</td>\n","      <td>0.320468</td>\n","    </tr>\n","    <tr>\n","      <th>17437</th>\n","      <td>0.698925</td>\n","      <td>0.791572</td>\n","      <td>0.320468</td>\n","    </tr>\n","    <tr>\n","      <th>17438</th>\n","      <td>0.978495</td>\n","      <td>0.791572</td>\n","      <td>0.320468</td>\n","    </tr>\n","    <tr>\n","      <th>17439</th>\n","      <td>0.612903</td>\n","      <td>0.791572</td>\n","      <td>0.320468</td>\n","    </tr>\n","    <tr>\n","      <th>17440</th>\n","      <td>0.666667</td>\n","      <td>0.791572</td>\n","      <td>0.320468</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>17441 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4a97b0b9-b00a-4c9f-93e1-31fa0c2fc019')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-4a97b0b9-b00a-4c9f-93e1-31fa0c2fc019 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4a97b0b9-b00a-4c9f-93e1-31fa0c2fc019');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["       sex\n","0        1\n","1        0\n","2        1\n","3        0\n","4        1\n","...    ...\n","17436    0\n","17437    1\n","17438    0\n","17439    1\n","17440    1\n","\n","[17441 rows x 1 columns]"],"text/html":["\n","  <div id=\"df-a25a56e8-0295-48e7-b2fc-8ead8ecb9813\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sex</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>17436</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>17437</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>17438</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>17439</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>17440</th>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>17441 rows × 1 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a25a56e8-0295-48e7-b2fc-8ead8ecb9813')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a25a56e8-0295-48e7-b2fc-8ead8ecb9813 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a25a56e8-0295-48e7-b2fc-8ead8ecb9813');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["       MI  STTC  CD  HYP\n","0       0     0   0    0\n","1       0     0   0    0\n","2       0     0   0    0\n","3       0     0   0    0\n","4       0     0   0    0\n","...    ..   ...  ..  ...\n","17436   0     0   1    0\n","17437   0     1   0    0\n","17438   0     0   0    0\n","17439   0     1   0    0\n","17440   0     0   0    0\n","\n","[17441 rows x 4 columns]"],"text/html":["\n","  <div id=\"df-6ee9596f-5e26-46ba-ab69-0fc7ee902425\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>MI</th>\n","      <th>STTC</th>\n","      <th>CD</th>\n","      <th>HYP</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>17436</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>17437</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>17438</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>17439</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>17440</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>17441 rows × 4 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6ee9596f-5e26-46ba-ab69-0fc7ee902425')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-6ee9596f-5e26-46ba-ab69-0fc7ee902425 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-6ee9596f-5e26-46ba-ab69-0fc7ee902425');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["       sub_NORM  sub_IMI  sub_STTC  sub_NST_  sub_LVH  sub_LAFB/LPFB  sub_RVH  \\\n","0             1        0         0         0        0              0        0   \n","1             1        0         0         0        0              0        0   \n","2             1        0         0         0        0              0        0   \n","3             1        0         0         0        0              0        0   \n","4             1        0         0         0        0              0        0   \n","...         ...      ...       ...       ...      ...            ...      ...   \n","17436         0        0         0         0        0              1        0   \n","17437         0        0         1         0        0              0        0   \n","17438         1        0         0         0        0              0        0   \n","17439         0        0         0         0        0              0        0   \n","17440         1        0         0         0        0              0        0   \n","\n","       sub_RAO/RAE  sub_IRBBB  sub_IVCD  ...  sub_ISCA  sub_ISC_  sub_SEHYP  \\\n","0                0          0         0  ...         0         0          0   \n","1                0          0         0  ...         0         0          0   \n","2                0          0         0  ...         0         0          0   \n","3                0          0         0  ...         0         0          0   \n","4                0          0         0  ...         0         0          0   \n","...            ...        ...       ...  ...       ...       ...        ...   \n","17436            0          0         1  ...         0         0          0   \n","17437            0          0         0  ...         0         0          0   \n","17438            0          0         0  ...         0         0          0   \n","17439            0          0         0  ...         1         0          0   \n","17440            0          0         0  ...         0         0          0   \n","\n","       sub_ISCI  sub_CRBBB  sub_CLBBB  sub_LAO/LAE  sub_ILBBB  sub_WPW  \\\n","0             0          0          0            0          0        0   \n","1             0          0          0            0          0        0   \n","2             0          0          0            0          0        0   \n","3             0          0          0            0          0        0   \n","4             0          0          0            0          0        0   \n","...         ...        ...        ...          ...        ...      ...   \n","17436         0          0          0            0          0        0   \n","17437         0          0          0            0          0        0   \n","17438         0          0          0            0          0        0   \n","17439         0          0          0            0          0        0   \n","17440         0          0          0            0          0        0   \n","\n","       sub_PMI  \n","0            0  \n","1            0  \n","2            0  \n","3            0  \n","4            0  \n","...        ...  \n","17436        0  \n","17437        0  \n","17438        0  \n","17439        0  \n","17440        0  \n","\n","[17441 rows x 23 columns]"],"text/html":["\n","  <div id=\"df-486b5395-d425-4f48-8887-a16baea4d64b\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sub_NORM</th>\n","      <th>sub_IMI</th>\n","      <th>sub_STTC</th>\n","      <th>sub_NST_</th>\n","      <th>sub_LVH</th>\n","      <th>sub_LAFB/LPFB</th>\n","      <th>sub_RVH</th>\n","      <th>sub_RAO/RAE</th>\n","      <th>sub_IRBBB</th>\n","      <th>sub_IVCD</th>\n","      <th>...</th>\n","      <th>sub_ISCA</th>\n","      <th>sub_ISC_</th>\n","      <th>sub_SEHYP</th>\n","      <th>sub_ISCI</th>\n","      <th>sub_CRBBB</th>\n","      <th>sub_CLBBB</th>\n","      <th>sub_LAO/LAE</th>\n","      <th>sub_ILBBB</th>\n","      <th>sub_WPW</th>\n","      <th>sub_PMI</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>17436</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>17437</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>17438</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>17439</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>17440</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>17441 rows × 23 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-486b5395-d425-4f48-8887-a16baea4d64b')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-486b5395-d425-4f48-8887-a16baea4d64b button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-486b5395-d425-4f48-8887-a16baea4d64b');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["       NORM\n","0         1\n","1         1\n","2         1\n","3         1\n","4         1\n","...     ...\n","17436     0\n","17437     0\n","17438     1\n","17439     0\n","17440     1\n","\n","[17441 rows x 1 columns]"],"text/html":["\n","  <div id=\"df-bce53c01-4aed-4dfd-95f7-f853024f497c\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>NORM</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>17436</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>17437</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>17438</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>17439</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>17440</th>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>17441 rows × 1 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bce53c01-4aed-4dfd-95f7-f853024f497c')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-bce53c01-4aed-4dfd-95f7-f853024f497c button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-bce53c01-4aed-4dfd-95f7-f853024f497c');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]},{"cell_type":"code","source":["signal=np.array(train_signal)\n","# signal.shape\n","target=np.array(train_bclass)\n","# target.shape\n","v_signal=np.array(valid_signal)\n","# v_signal.shape\n","v_target=np.array(valid_bclass)\n","# v_target.shape\n","t_signal=np.array(test_signal)\n","# t_signal.shape\n","t_target=np.array(test_bclass)\n","# t_target.shape"],"metadata":{"id":"V9y39lDn3VjF","executionInfo":{"status":"ok","timestamp":1674150877014,"user_tz":-330,"elapsed":1775,"user":{"displayName":"ABDUL HAQUE","userId":"03599932539934700066"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n","import numpy as np\n","from keras_preprocessing.sequence import pad_sequences\n","from keras_preprocessing.text import Tokenizer\n","from keras import backend as K"],"metadata":{"id":"vzDLp8b99fwI","executionInfo":{"status":"ok","timestamp":1674150894168,"user_tz":-330,"elapsed":871,"user":{"displayName":"ABDUL HAQUE","userId":"03599932539934700066"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["## utility"],"metadata":{"id":"illGv1cP9Mmf"}},{"cell_type":"code","source":["class utility:\n","\n","    def read_CSV(self, filename):\n","        df = pd.read_csv(filename)\n","        return df\n","\n","    def get_text_label(self, df):\n","        texts = []  # list of text samples\n","        labels = []  # list of label ids\n","        for index, row in df.iterrows():\n","            if isinstance(row['sentence'], float):\n","                texts.append(str(row['sentence']))\n","            else:\n","                texts.append(row['sentence'])\n","\n","            labels.append(row['label'])\n","\n","        return texts, labels\n","\n","    # def tokenize_texts(self, texts):\n","    #     tokenizer = Tokenizer(num_words=10000)\n","    #     tokenizer.fit_on_texts(texts)\n","\n","        # return tokenizer\n","\n","    # def padding_texts(self, texts, maxlen):\n","\n","    #     texts = pad_sequences(texts, padding='post', maxlen=maxlen)\n","\n","    #     return texts\n","\n","    def get_metric(self, y_true, y_pred):\n","        accuracyScore = accuracy_score(y_true, y_pred)\n","\n","        # binary: Only report results for the class specified by pos_label. This is applicable only if targets (y_{true,pred}) are binary.\n","        precisionScoreBinary = precision_score(y_true, y_pred, average='binary')\n","        recallScoreBinary = recall_score(y_true, y_pred, average='binary')\n","        f1ScoreBinary = f1_score(y_true, y_pred, average='binary')\n","\n","        return accuracyScore, precisionScoreBinary, recallScoreBinary, f1ScoreBinary\n","\n","    def print_metric(self, accuracyScore, precisionScoreBinary, recallScoreBinary, f1ScoreBinary):\n","        print(\"Accuracy: \" + str(accuracyScore))\n","        print(\"Precision: \" + str(precisionScoreBinary))\n","        print(\"Recall: \" + str(recallScoreBinary))\n","        print(\"F1-Score: \" + str(f1ScoreBinary))\n","        print(str(accuracyScore) + \",\" + str(precisionScoreBinary) + \",\" + str(recallScoreBinary) + \",\" + str(\n","            f1ScoreBinary))\n","\n","    def get_testing_metric(self, y_test, y_pred):\n","        # metric for Testing Data\n","        # print(\"Testing Data\")\n","        accuracyScore, precisionScoreBinary, recallScoreBinary, f1ScoreBinary = self.get_metric(y_test, y_pred)\n","        # print()\n","\n","        return accuracyScore, precisionScoreBinary, recallScoreBinary, f1ScoreBinary\n","\n","    def write_df_csv(self, df, out_path):\n","        df.to_csv(out_path, index=False)\n","\n","    # def create_embedding_matrix(self, filepath, word_index, embedding_dim):\n","    #     vocab_size = len(word_index) + 1  # Adding again 1 because of reserved 0 index\n","    #     embedding_matrix = np.zeros((vocab_size, embedding_dim))\n","\n","    #     with open(filepath, encoding=\"utf8\") as f:\n","    #         for line in f:\n","    #             word, *vector = line.split()\n","    #             if word in word_index:\n","    #                 idx = word_index[word]\n","    #                 embedding_matrix[idx] = np.array(\n","    #                     vector, dtype=np.float32)[:embedding_dim]\n","\n","    #     return embedding_matrix\n","\n","    # def get_max_length_of_sentences(self, texts):\n","    #     maxlength = 0\n","    #     for text in texts:\n","    #         if (len(text.split()) > maxlength):\n","    #             maxlength = len(text.split())\n","\n","    #     return maxlength\n","\n","    def get_training_trial_data(self, textsTraining, labelsTraining, textsTrial, labelsTrial):\n","        X_train, X_val = np.asarray(textsTraining), np.asarray(textsTrial)\n","        y_train, y_val = np.asarray(labelsTraining), np.asarray(labelsTrial)\n","\n","        # Tokenize words\n","        # tokenizer = self.tokenize_texts(textsTraining)\n","        # X_train = tokenizer.texts_to_sequences(textsTraining)\n","        # X_val = tokenizer.texts_to_sequences(textsTesting)\n","\n","        # Adding 1 because of reserved 0 index\n","        # vocab_size = len(tokenizer.word_index) + 1\n","\n","        # get maxlen\n","        # maxlen = self.get_max_length_of_sentences(textsTraining)\n","\n","        # # Pad sequences with zeros\n","        # X_train = self.padding_texts(X_train, maxlen)\n","        # X_val = self.padding_texts(X_val, maxlen)\n","\n","        # embedding_matrix = []\n","        # embedding_matrix.append(self.create_embedding_matrix(glovePath[0], tokenizer.word_index, 50))\n","        # embedding_matrix.append(self.create_embedding_matrix(glovePath[1], tokenizer.word_index, 100))\n","        # embedding_matrix.append(self.create_embedding_matrix(glovePath[2], tokenizer.word_index, 200))\n","        # embedding_matrix.append(self.create_embedding_matrix(glovePath[3], tokenizer.word_index, 300))\n","\n","        return X_train, X_val, y_train, y_val\n","\n","    def Average(self, list):\n","        return sum(list) / len(list)\n","    \n","    def recall_m(self, y_true, y_pred):\n","        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n","        recall = true_positives / (possible_positives + K.epsilon())\n","        return recall\n","\n","    def precision_m(self, y_true, y_pred):\n","        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n","        precision = true_positives / (predicted_positives + K.epsilon())\n","        return precision\n","\n","    def f1_m(self, y_true, y_pred):\n","        precision = self.precision_m(y_true, y_pred)\n","        recall = self.recall_m(y_true, y_pred)\n","        return 2*((precision*recall)/(precision+recall+K.epsilon()))"],"metadata":{"id":"Pj8Sv8g79MSI","executionInfo":{"status":"ok","timestamp":1674151064719,"user_tz":-330,"elapsed":660,"user":{"displayName":"ABDUL HAQUE","userId":"03599932539934700066"}}},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":["## Finate state machine"],"metadata":{"id":"HuciNeaW8hEj"}},{"cell_type":"code","source":["import random\n","\n","def FSM():\n","    fsm = {}\n","    fsm[0] = {'src': 0, 'dst': 1, 'layer': 'embedding_layer', 'next_path': [1]}\n","    fsm[1] = {'src': 1, 'dst': 2, 'layer': 'convolutional_layer', 'next_path': [2, 3, 5]}\n","    fsm[2] = {'src': 2, 'dst': 2, 'layer': 'convolutional_layer', 'next_path': [2, 3, 5]}\n","    fsm[3] = {'src': 2, 'dst': 3, 'layer': 'maxpooling_layer', 'next_path': [4]}\n","    fsm[4] = {'src': 3, 'dst': 2, 'layer': 'convolutional_layer', 'next_path': [2, 3, 5]}\n","    fsm[5] = {'src': 2, 'dst': 4, 'layer': 'global_maxpooling_layer', 'next_path': [6, 7]}\n","    fsm[6] = {'src': 4, 'dst': 5, 'layer': 'dense_layer', 'next_path': [8, 9, 11]}\n","    fsm[7] = {'src': 4, 'dst': 6, 'layer': 'dropout_layer', 'next_path': [10, 12]}\n","    fsm[8] = {'src': 5, 'dst': 5, 'layer': 'dense_layer', 'next_path': [8, 9, 11]}\n","    fsm[9] = {'src': 5, 'dst': 6, 'layer': 'dropout_layer', 'next_path': [10, 12]}\n","    fsm[10] = {'src': 6, 'dst': 5, 'layer': 'dense_layer', 'next_path': [8, 9, 11]}\n","    fsm[11] = {'src': 5, 'dst': 7, 'layer': 'output_layer', 'next_path': []}\n","    fsm[12] = {'src': 6, 'dst': 7, 'layer': 'output_layer', 'next_path': []}\n","\n","    return fsm\n","\n","def mutateFSM():\n","    fsm = {}\n","    fsm['convolutional_layer'] = {'before': ['convolutional_layer'],\n","                                  'after': ['convolutional_layer'], 'change': 'maxpooling_layer'}\n","    fsm['maxpooling_layer'] = {'before': ['convolutional_layer'],\n","                               'after': ['convolutional_layer'], 'change': 'convolutional_layer'}\n","    fsm['dense_layer'] = {'before': ['global_maxpooling_layer', 'dense_layer'],\n","                          'after': ['dense_layer'], 'change': 'dropout_layer'}\n","    fsm['dropout_layer'] = {'before': ['global_maxpooling_layer', 'dense_layer'],\n","                            'after': ['dense_layer'], 'change': 'dense_layer'}\n","\n","    return fsm\n","\n","def addFSM():\n","    fsm = {}\n","    fsm['convolutional_layer'] = {'before': ['convolutional_layer'],\n","                                  'add': ['convolutional_layer', 'maxpooling_layer']}\n","    fsm['maxpooling_layer'] = {'before': ['convolutional_layer'],\n","                               'add': ['convolutional_layer']}\n","    fsm['dense_layer'] = {'before': ['global_maxpooling_layer', 'dense_layer'],\n","                          'add': ['dense_layer', 'dropout_layer']}\n","    fsm['dropout_layer'] = {'before': ['global_maxpooling_layer', 'dense_layer'],\n","                            'add': ['dense_layer']}\n","\n","    return fsm\n","\n","def addConvLayer(idx, toolbox, toolboxes, defaultVal, layerparameters):\n","    toolbox.register('num_filters' + str(idx), layerparameters['num_filters'][0],\n","                     layerparameters['num_filters'][1], layerparameters['num_filters'][2])\n","    toolboxes.append(toolbox.__getattribute__('num_filters' + str(idx)))\n","    toolbox.register('kernel_size' + str(idx), layerparameters['kernel_size'][0],\n","                     layerparameters['kernel_size'][1], layerparameters['kernel_size'][2])\n","    toolboxes.append(toolbox.__getattribute__('kernel_size' + str(idx)))\n","    toolbox.register('conv_activation_func' + str(idx), layerparameters['conv_activation_func'][0],\n","                     layerparameters['conv_activation_func'][1])\n","    toolboxes.append(toolbox.__getattribute__('conv_activation_func' + str(idx)))\n","    toolbox.register('conv_init_mode' + str(idx), layerparameters['conv_init_mode'][0],\n","                     layerparameters['conv_init_mode'][1])\n","    toolboxes.append(toolbox.__getattribute__('conv_init_mode' + str(idx)))\n","    toolbox.register('conv_weight_constraint' + str(idx), layerparameters['conv_weight_constraint'][0],\n","                     layerparameters['conv_weight_constraint'][1], layerparameters['conv_weight_constraint'][2])\n","    toolboxes.append(toolbox.__getattribute__('conv_weight_constraint' + str(idx)))\n","\n","    defaultVal.update({'num_filters' + str(idx): 64})\n","    defaultVal.update({'kernel_size' + str(idx): 3})\n","    defaultVal.update({'conv_activation_func' + str(idx): \"relu\"})\n","    defaultVal.update({'conv_init_mode' + str(idx): \"glorot_uniform\"})\n","    defaultVal.update({'conv_weight_constraint' + str(idx): 3})\n","\n","\n","def addDenseLayer(idx, toolbox, toolboxes, defaultVal, layerparameters):\n","    toolbox.register('neurons' + str(idx), layerparameters['neurons'][0],\n","                     layerparameters['neurons'][1], layerparameters['neurons'][2])\n","    toolboxes.append(toolbox.__getattribute__('neurons' + str(idx)))\n","    toolbox.register('dense_activation_func' + str(idx), layerparameters['dense_activation_func'][0],\n","                     layerparameters['dense_activation_func'][1])\n","    toolboxes.append(toolbox.__getattribute__('dense_activation_func' + str(idx)))\n","    toolbox.register('dense_init_mode' + str(idx), layerparameters['dense_init_mode'][0],\n","                     layerparameters['dense_init_mode'][1])\n","    toolboxes.append(toolbox.__getattribute__('dense_init_mode' + str(idx)))\n","    toolbox.register('dense_weight_constraint' + str(idx), layerparameters['dense_weight_constraint'][0],\n","                     layerparameters['dense_weight_constraint'][1], layerparameters['dense_weight_constraint'][2])\n","    toolboxes.append(toolbox.__getattribute__('dense_weight_constraint' + str(idx)))\n","\n","    defaultVal.update({'neurons' + str(idx): 1})\n","    defaultVal.update({'dense_activation_func' + str(idx): \"relu\"})\n","    defaultVal.update({'dense_init_mode' + str(idx): \"glorot_uniform\"})\n","    defaultVal.update({'dense_weight_constraint' + str(idx): 3})\n","\n","\n","def addMaxPoolingLayer(idx, toolbox, toolboxes, defaultVal, layerparameters):\n","    toolbox.register('pool_size' + str(idx), layerparameters['pool_size'][0],\n","                     layerparameters['pool_size'][1], layerparameters['pool_size'][2])\n","    toolboxes.append(toolbox.__getattribute__('pool_size' + str(idx)))\n","\n","    defaultVal.update({'pool_size' + str(idx): 5})\n","\n","\n","def addDropoutLayer(idx, toolbox, toolboxes, defaultVal, layerparameters):\n","    toolbox.register('dropout_rate' + str(idx), layerparameters['dropout_rate'][0],\n","                     layerparameters['dropout_rate'][1], layerparameters['dropout_rate'][2])\n","    toolboxes.append(toolbox.__getattribute__('dropout_rate' + str(idx)))\n","\n","    defaultVal.update({'dropout_rate' + str(idx): 0.2})\n","\n","def getLayerSize(layer, conv_idx, dense_idx, dropout_idx, maxpooling_idx):\n","    if layer == 'convolutional_layer':\n","        conv_idx += 1\n","    elif layer == 'dense_layer':\n","        dense_idx += 1\n","    elif layer == 'dropout_layer':\n","        dropout_idx += 1\n","    elif layer == 'maxpooling_layer':\n","        maxpooling_idx += 1\n","    return conv_idx, dense_idx, dropout_idx, maxpooling_idx\n","\n","\n","def getMaxLayerSize(conv_idx, dense_idx, dropout_idx, maxpooling_idx, max_conv_idx, max_dense_idx, max_dropout_idx,\n","                    max_maxpooling_idx):\n","    if conv_idx > max_conv_idx:\n","        max_conv_idx = conv_idx\n","    if dense_idx > max_dense_idx:\n","        max_dense_idx = dense_idx\n","    if dropout_idx > max_dropout_idx:\n","        max_dropout_idx = dropout_idx\n","    if maxpooling_idx > max_maxpooling_idx:\n","        max_maxpooling_idx = maxpooling_idx\n","\n","    return max_conv_idx, max_dense_idx, max_dropout_idx, max_maxpooling_idx\n","\n","\n","def addLayerToolboxes(max_conv_idx, max_dense_idx, max_dropout_idx, max_maxpooling_idx, toolbox, toolboxes, defaultVal,\n","                      layerparameters):\n","    idx = 0\n","    while idx < max_conv_idx:\n","        idx += 1\n","        addConvLayer(idx, toolbox, toolboxes, defaultVal, layerparameters)\n","\n","    idx = 0\n","    while idx < max_dense_idx:\n","        idx += 1\n","        addDenseLayer(idx, toolbox, toolboxes, defaultVal, layerparameters)\n","\n","    idx = 0\n","    while idx < max_maxpooling_idx:\n","        idx += 1\n","        addMaxPoolingLayer(idx, toolbox, toolboxes, defaultVal, layerparameters)\n","\n","    idx = 0\n","    while idx < max_dropout_idx:\n","        idx += 1\n","        addDropoutLayer(idx, toolbox, toolboxes, defaultVal, layerparameters)\n","\n","\n","def generateFSM(n_pop, layerparameters, toolbox, toolboxes, defaultVal):\n","    fsm = FSM()\n","\n","    path_ind = {}\n","    max_conv_idx = 0\n","    max_dense_idx = 0\n","    max_dropout_idx = 0\n","    max_maxpooling_idx = 0\n","\n","    for ind in range(0, n_pop):\n","        idx = conv_idx = dense_idx = dropout_idx = maxpooling_idx = 0\n","        path = [fsm[idx]['layer']]\n","        while len(fsm[idx]['next_path']) != 0:\n","            idx = random.choice(fsm[idx]['next_path'])\n","            layer = fsm[idx]['layer']\n","            path.append(layer)\n","            conv_idx, dense_idx, dropout_idx, maxpooling_idx = getLayerSize(layer, conv_idx, dense_idx, dropout_idx,\n","                                                                            maxpooling_idx)\n","\n","        max_conv_idx, max_dense_idx, max_dropout_idx, max_maxpooling_idx = getMaxLayerSize(conv_idx, dense_idx,\n","                                                                                           dropout_idx, maxpooling_idx,\n","                                                                                           max_conv_idx, max_dense_idx,\n","                                                                                           max_dropout_idx,\n","                                                                                           max_maxpooling_idx)\n","\n","        path_ind[ind] = path\n","\n","    addLayerToolboxes(max_conv_idx, max_dense_idx, max_dropout_idx, max_maxpooling_idx, toolbox, toolboxes, defaultVal,\n","                      layerparameters)\n","\n","    return path_ind, max_conv_idx, max_maxpooling_idx, max_dense_idx, max_dropout_idx\n","\n","\n","def openFSM(df, layerparameters, toolbox, toolboxes, defaultVal):\n","    path_ind = {}\n","    fitnesses = []\n","\n","    hyperparams = [s for s in list(df.columns) if not 'Unnamed' in s]\n","\n","    max_conv_idx = sum('num_filters' in s for s in hyperparams)\n","    max_dense_idx = sum('neurons' in s for s in hyperparams)\n","    max_dropout_idx = sum('dropout_rate' in s for s in hyperparams)\n","    max_maxpooling_idx = sum('pool_size' in s for s in hyperparams)\n","\n","    for index, row in df.iterrows():\n","        path = [s for s in row if 'layer' in str(s)]\n","        fitness = [s for s in row if str(s).replace('.', '', 1).isdigit()]\n","        fitnesses.append(tuple([float(fitness[0])]))\n","        path_ind[index] = path\n","\n","    addLayerToolboxes(max_conv_idx, max_dense_idx, max_dropout_idx, max_maxpooling_idx, toolbox, toolboxes, defaultVal,\n","                      layerparameters)\n","\n","    return path_ind, fitnesses, max_conv_idx, max_maxpooling_idx, max_dense_idx, max_dropout_idx"],"metadata":{"id":"tx3ZPKfF3lXm","executionInfo":{"status":"ok","timestamp":1674150756429,"user_tz":-330,"elapsed":805,"user":{"displayName":"ABDUL HAQUE","userId":"03599932539934700066"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["## CNN"],"metadata":{"id":"VmvEvPtm85uT"}},{"cell_type":"code","source":["import tensorflow as tf\n","\n","\n","class CNN:\n","\n","    def cnn_model(self,  indiv, path):\n","        model = tf.keras.models.Sequential()\n","        conv_idx = dense_idx = dropout_idx = maxpooling_idx = 0\n","        for layer in path:\n","            # if layer == 'embedding_layer':\n","            #     model.add(\n","            #         tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=indiv['output_dim'],\n","            #                          weights=[embedding_matrix], input_length=maxlen, trainable=True))\n","            if layer == 'convolutional_layer':\n","                conv_idx += 1\n","                model.add(tf.keras.layers.Conv1D(indiv['num_filters' + str(conv_idx)], indiv['kernel_size' + str(conv_idx)],\n","                                        kernel_initializer=indiv['conv_init_mode' + str(conv_idx)],\n","                                        activation=indiv['conv_activation_func' + str(conv_idx)],\n","                                        kernel_constraint=tf.keras.constraints.max_norm(indiv['conv_weight_constraint' + str(conv_idx)]),\n","                                        data_format='channels_first'))\n","            elif layer == 'dense_layer':\n","                dense_idx += 1\n","                model.add(tf.keras.layers.Dense(indiv['neurons' + str(dense_idx)],\n","                                       kernel_initializer=indiv['dense_init_mode' + str(dense_idx)],\n","                                       activation=indiv['dense_activation_func' + str(dense_idx)],\n","                                       kernel_constraint=tf.keras.constraints.max_norm(indiv['dense_weight_constraint' + str(dense_idx)])))\n","            elif layer == 'dropout_layer':\n","                dropout_idx += 1\n","                model.add(tf.keras.layers.Dropout(indiv['dropout_rate' + str(dropout_idx)]))\n","            elif layer == 'maxpooling_layer':\n","                maxpooling_idx += 1\n","                model.add(tf.keras.layers.MaxPooling1D(indiv['pool_size' + str(maxpooling_idx)]))\n","            elif layer == 'global_maxpooling_layer':\n","                model.add(tf.keras.layers.GlobalMaxPooling1D())\n","            elif layer == 'output_layer':\n","                model.add(tf.keras.layers.Dense(1, kernel_initializer=indiv['output_init_mode'], activation='sigmoid'))\n","\n","        if indiv['optimizer'] == 'sgd':\n","            opt = tf.keras.optimizers.SGD(lr=indiv['learning_rate'], momentum=indiv['momentum'], decay=0.0,\n","                                 nesterov=False)\n","        elif indiv['optimizer'] == 'rmsprop':\n","            opt = tf.keras.optimizers.RMSprop(lr=indiv['learning_rate'], rho=0.9, epsilon=None, decay=0.0)\n","        elif indiv['optimizer'] == 'adagrad':\n","            opt = tf.keras.optimizers.Adagrad(lr=indiv['learning_rate'], epsilon=None, decay=0.0)\n","        elif indiv['optimizer'] == 'adadelta':\n","            opt = tf.keras.optimizers.Adadelta(lr=indiv['learning_rate'], rho=0.95, epsilon=None, decay=0.0)\n","        elif indiv['optimizer'] == 'adam':\n","            opt = tf.keras.optimizers.Adam(lr=indiv['learning_rate'], beta_1=0.9, beta_2=0.999, epsilon=None,\n","                                  decay=0.0, amsgrad=False)\n","        elif indiv['optimizer'] == 'adamax':\n","            opt = tf.keras.optimizers.Adamax(lr=indiv['learning_rate'], beta_1=0.9, beta_2=0.999, epsilon=None,\n","                                    decay=0.0)\n","        elif indiv['optimizer'] == 'nadam':\n","            opt = tf.keras.optimizers.Nadam(lr=indiv['learning_rate'], beta_1=0.9, beta_2=0.999, epsilon=None,\n","                                   schedule_decay=0.004)\n","        \n","\n","        util=utility()\n","        model.compile(optimizer=opt, loss='binary_crossentropy', metrics=[util.f1_m])\n","\n","        return model"],"metadata":{"id":"uYpAhmIt8lh0","executionInfo":{"status":"ok","timestamp":1674150759870,"user_tz":-330,"elapsed":895,"user":{"displayName":"ABDUL HAQUE","userId":"03599932539934700066"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["import collections\n","import os\n","from time import sleep\n","\n","util = utility()\n","cnn = CNN()\n","\n","def FitnessCalculation(individual, cfold, defaultVal, resultsPath, testing_name):\n","    indiv = collections.OrderedDict()\n","    i = 0\n","    for key in defaultVal.keys():\n","        indiv[key] = individual[i]\n","        i += 1\n","\n","    path = individual[len(defaultVal):len(individual)]\n","\n","    return crossfold(indiv, path, cfold, resultsPath, testing_name)\n","\n","\n","def crossfold(indiv, path, fold, resultsPath, testing_name):\n","    # if indiv['output_dim'] == 50:\n","    #     embedding_mtx = fold['embedding_matrix'][0]\n","    # elif indiv['output_dim'] == 100:\n","    #     embedding_mtx = fold['embedding_matrix'][1]\n","    # elif indiv['output_dim'] == 200:\n","    #     embedding_mtx = fold['embedding_matrix'][2]\n","    # elif indiv['output_dim'] == 300:\n","    #     embedding_mtx = fold['embedding_matrix'][3]\n","\n","    model = cnn.cnn_model(indiv, path)\n","    \n","    #early stopping\n","    callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_f1_m', mode='max', verbose=True, patience=10)]\n","\n","    #save the best model\n","    callbacks += [tf.keras.callbacks.ModelCheckpoint(resultsPath + testing_name + \".h5\", monitor='val_f1_m', mode='max', verbose=False, \n","                                  save_best_only=True)]\n","\n","    class_weight = {0: 0.25,\n","                    1: 0.75}\n","    model.fit(fold['X_train'], fold['y_train'], epochs=indiv['epochs'], verbose=False, \n","              validation_data=(fold['X_val'], fold['y_val']), use_multiprocessing=False,\n","              batch_size=indiv['batch_size'], callbacks=callbacks, class_weight=class_weight)\n","    \n","    dependencies = {\n","    'f1_m': util.f1_m\n","    }\n","\n","    # load the saved model\n","    for x in range(0, 4):  # try 4 times\n","        try:\n","            # msg.send()\n","            saved_model = tf.keras.models.load_model(resultsPath + testing_name + \".h5\", custom_objects=dependencies)\n","            str_error = None\n","        except Exception as e:\n","            print('An error occurs when loading saved model.')\n","            str_error = e\n","            pass\n","\n","        if str_error:\n","            sleep(2)  # wait for 2 seconds before trying to fetch the data again\n","        else:\n","            break\n","    \n","\n","    y_pred = saved_model.predict_classes(fold['X_val'])\n","\n","    os.remove(resultsPath + testing_name + \".h5\")\n","\n","    # CNN metrics\n","    accuracyScore, precisionScoreBinary, recallScoreBinary, f1ScoreBinary = util.get_testing_metric(fold['y_val'],\n","                                                                                                    y_pred)\n","    return f1ScoreBinary"],"metadata":{"id":"u4kKNmYZ_1Tk","executionInfo":{"status":"ok","timestamp":1674150763846,"user_tz":-330,"elapsed":608,"user":{"displayName":"ABDUL HAQUE","userId":"03599932539934700066"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["## genetic algo"],"metadata":{"id":"DnfjLk0ZDVUM"}},{"cell_type":"code","source":["pip install deap"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PSKQw9c-D9PX","executionInfo":{"status":"ok","timestamp":1674146493947,"user_tz":-330,"elapsed":4226,"user":{"displayName":"ABDUL HAQUE","userId":"03599932539934700066"}},"outputId":"d80c6cb2-0340-4f91-aa48-340a6a6289fd"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting deap\n","  Downloading deap-1.3.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (139 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.9/139.9 KB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from deap) (1.21.6)\n","Installing collected packages: deap\n","Successfully installed deap-1.3.3\n"]}]},{"cell_type":"code","source":["import random\n","from operator import attrgetter\n","from deap import base\n","from deap import creator\n","from deap import tools\n","import time\n","import datetime\n","import math\n","from scipy.spatial import distance\n","import itertools\n","\n","\n","class GeneticAlgorithm:\n","    __slots__ = (\n","        \"toolbox\", \"toolboxes\", \"cross_rate\", \"mut_rate\", \"n_pop\", \"n_gen\", \"resultsPath\", \"testing_name\", \"cfold\",\n","        \"globalparameters\", \"layerparameters\", \"defaultVal\", \"path_ind\", \"max_conv_idx\", \"max_maxpooling_idx\",\n","        \"max_dense_idx\", \"max_dropout_idx\")\n","\n","    def __init__(self, toolbox, toolboxes, cross_rate, mut_rate, n_pop, n_gen, resultsPath, testing_name,\n","                 cfold, globalparameters, layerparameters, defaultVal, path_ind, max_conv_idx, max_maxpooling_idx,\n","                 max_dense_idx, max_dropout_idx):\n","        self.toolbox = toolbox\n","        self.toolboxes = toolboxes\n","        self.cross_rate = cross_rate\n","        self.mut_rate = mut_rate\n","        self.n_pop = n_pop\n","        self.n_gen = n_gen\n","        self.resultsPath = resultsPath\n","        self.testing_name = testing_name\n","        self.cfold = cfold\n","        self.globalparameters = globalparameters\n","        self.layerparameters = layerparameters\n","        self.defaultVal = defaultVal\n","        self.path_ind = path_ind\n","        self.max_conv_idx = max_conv_idx\n","        self.max_maxpooling_idx = max_maxpooling_idx\n","        self.max_dense_idx = max_dense_idx\n","        self.max_dropout_idx = max_dropout_idx\n","\n","    def fitnessCalc(self, individual):\n","        i = 0\n","        if len(individual.fitness.values) == 0:\n","            if (0 in individual or '' in individual or 'False' in individual or None in individual):\n","                for param in self.defaultVal:\n","                    if individual[i] == 0 or individual[i] == '' or individual[i] == 'False' or individual[i] == None:\n","                        individual[i] = self.defaultVal[param]\n","                    i += 1\n","\n","            fc = FitnessCalculation(individual, self.cfold, self.defaultVal, self.resultsPath, self.testing_name)\n","        else:\n","            fc = individual.fitness.values[0]\n","        print('{} {}'.format(datetime.datetime.now(), fc))\n","        return fc,\n","\n","    def write_result(self):\n","        # Create Testing Results\n","        f = open(self.resultsPath + self.testing_name + \".csv\", \"a+\")\n","        text = \"i,min,max,mean,std,avgdistance,time,CR,MR\"\n","        for param in self.defaultVal:\n","            text += \",{0}\".format(param)\n","        text += \"\\n\"       \n","        f.write(text)\n","        f.close()\n","\n","        # Create Last Population file\n","        f = open(self.resultsPath + self.testing_name + \"lastpop.csv\", 'a+')\n","        text = \"i,f1score\"\n","        for param in self.defaultVal:\n","            text += \",{0}\".format(param)\n","        text += \"\\n\"\n","        f.write(text)\n","        f.close()\n","\n","    def std_calc(self, fits, length):\n","        mean = sum(fits) / length\n","        sum2 = sum(x * x for x in fits)\n","        std = abs(sum2 / length - mean ** 2) ** 0.5\n","\n","        return mean, std\n","    \n","    def distance_calc(self, pop):\n","        distances = []\n","        for subset in itertools.combinations(pop, 2):\n","            distances.append(distance.hamming(subset[0][0:subset[0].index('embedding_layer')],\n","                                              subset[1][0:subset[1].index('embedding_layer')]))\n","\n","        avgDistance = sum(distances) / len(distances)\n","        \n","        return avgDistance\n","\n","    def invalid_fitness_calc(self, pop):\n","        # Evaluate the individuals with an invalid fitness\n","        invalid_ind = [ind for ind in pop if not ind.fitness.valid]\n","        fitnesses = map(self.toolbox.evaluate, invalid_ind)\n","        for ind, fit in zip(invalid_ind, fitnesses):\n","            ind.fitness.values = fit\n","\n","    def mutHyperparam(self, individual, indpb):\n","        toolboxesSize = len(self.toolboxes)\n","        fsm = FSM()\n","        mutatefsm = mutateFSM()\n","        addfsm = addFSM()\n","\n","        # Mutation for the Hyperparameter Chromosomes\n","        for i in range(toolboxesSize):\n","            if random.random() < indpb:\n","                if len(self.toolboxes[i].args) == 1:\n","                    individual[i] = self.toolboxes[i].func(self.toolboxes[i].args[0])\n","                else:\n","                    individual[i] = self.toolboxes[i].func(self.toolboxes[i].args[0], self.toolboxes[i].args[1])\n","\n","        # Mutation for the Architecture Chromosomes\n","        archChrom = individual[individual.index('convolutional_layer'):individual.index('output_layer')]\n","        size = len(archChrom)\n","\n","        for i in range(1, size):\n","            if random.random() < indpb:\n","                if (i>=size):\n","                  break\n","                \n","                if (archChrom[i] == 'global_maxpooling_layer'):\n","                  continue\n","\n","                selectMutType = random.randint(0, 2)\n","                # Remove the layer\n","                if selectMutType == 0:\n","                  for key in fsm:\n","                      if fsm[key]['layer'] in archChrom[i - 1:i]:\n","                          for j in fsm[key]['next_path']:\n","                              if i != size - 1 and i + 1 < size and fsm[j]['layer'] == archChrom[i + 1]:\n","                                  archChrom.remove(archChrom[i])\n","#                                   print('individual before remove', individual)\n","                                  individual[\n","                                  individual.index('convolutional_layer'):individual.index('output_layer')] = archChrom\n","#                                   print('individual after remove', individual)\n","                                  size -= 1          \n","                                  break\n","                          else:\n","                            continue\n","                          break                              \n","\n","                # Change the layer\n","                elif selectMutType == 1:\n","                    if i == size - 1:\n","                        if (archChrom[i] == 'dropout_layer') or (archChrom[i] == 'dense_layer' and 'dropout_layer' not in archChrom[i - 1:i]):\n","                            if (mutatefsm[archChrom[i]]['change'] == 'convolutional_layer' and individual.count(\n","                                    'convolutional_layer') < self.max_conv_idx) or (\n","                                    mutatefsm[archChrom[i]]['change'] == 'dense_layer' and individual.count('dense_layer')\n","                                    < self.max_dense_idx) or (\n","                                    mutatefsm[archChrom[i]]['change'] == 'maxpooling_layer' and individual.count(\n","                                'maxpooling_layer') < self.max_maxpooling_idx) or (\n","                                    mutatefsm[archChrom[i]]['change'] == 'dropout_layer' and individual.count('dropout_layer')\n","                                    < self.max_dropout_idx):\n","                                archChrom[i] = mutatefsm[archChrom[i]]['change']\n","#                                 print('individual before change', individual)\n","                                individual[\n","                                individual.index('convolutional_layer'):individual.index('output_layer')] = archChrom\n","#                                 print('individual after change', individual)\n","\n","                    else:\n","                        if all(item in mutatefsm[archChrom[i]]['before'] for item in archChrom[i - 1:i]) and archChrom[i + 1] in mutatefsm[archChrom[i]]['after']:\n","                            if (mutatefsm[archChrom[i]]['change'] == 'convolutional_layer' and individual.count(\n","                                    'convolutional_layer') < self.max_conv_idx) or (\n","                                    mutatefsm[archChrom[i]]['change'] == 'dense_layer' and individual.count('dense_layer')\n","                                    < self.max_dense_idx) or (\n","                                    mutatefsm[archChrom[i]]['change'] == 'maxpooling_layer' and individual.count(\n","                                'maxpooling_layer') < self.max_maxpooling_idx) or (\n","                                    mutatefsm[archChrom[i]]['change'] == 'dropout_layer' and individual.count('dropout_layer')\n","                                    < self.max_dropout_idx):\n","                                \n","                                archChrom[i] = mutatefsm[archChrom[i]]['change']\n","#                                 print('individual before change', individual)\n","                                individual[\n","                                individual.index('convolutional_layer'):individual.index('output_layer')] = archChrom\n","#                                 print('individual after change', individual)\n","                # Add a layer\n","                elif selectMutType == 2:\n","                    for key in addfsm:\n","                        if key in archChrom[i] and all(item in addfsm[archChrom[i]]['before'] for item in archChrom[i - 1:i]):\n","                            if ('convolutional_layer' in addfsm[archChrom[i]]['add'] and individual.count(\n","                                    'convolutional_layer') < self.max_conv_idx) or (\n","                                    'dense_layer' in addfsm[archChrom[i]]['add'] and individual.count('dense_layer') < self.max_dense_idx) or (\n","                                    'maxpooling_layer' in addfsm[archChrom[i]]['add'] and individual.count(\n","                                'maxpooling_layer') < self.max_maxpooling_idx) or (\n","                                    'dropout_layer' in addfsm[archChrom[i]]['add'] and individual.count(\n","                                'dropout_layer') < self.max_dropout_idx):\n","                                archChrom.insert(i, random.choice(addfsm[archChrom[i]]['add']))\n","#                                 print('individual before add', individual)\n","                                individual[\n","                                individual.index('convolutional_layer'):individual.index('output_layer')] = archChrom\n","#                                 print('individual after add', individual)\n","                        \n","        return individual,\n","\n","    def cxTwoPoint(self, ind1, ind2, pop, offspring):\n","        # Crossover for hyperparameter chromosomes\n","        size = ind1.index('embedding_layer')\n","        selectCxType = random.randint(0, 2)\n","        # One point crossover\n","        if selectCxType == 0:\n","#             print('ind1 before one-point crossover:', ind1)\n","#             print('ind2 before one-point crossover:', ind2)\n","            cxpoint = random.randint(1, size - 1)\n","            ind1[cxpoint:], ind2[cxpoint:] = ind2[cxpoint:], ind1[cxpoint:]\n","#             print('ind1 after one-point crossover:', ind1)\n","#             print('ind2 after one-point crossover:', ind2)\n","        # Two-point crossover\n","        elif selectCxType == 1:\n","#             print('ind1 before two-point crossover:', ind1)\n","#             print('ind2 before two-point crossover:', ind2)\n","            cxpoint1 = random.randint(1, size - 1)\n","            cxpoint2 = random.randint(1, size - 1)\n","            if cxpoint2 >= cxpoint1:\n","                cxpoint2 += 1\n","            else:  # Swap the two cx points\n","                cxpoint1, cxpoint2 = cxpoint2, cxpoint1\n","\n","            ind1[cxpoint1:cxpoint2], ind2[cxpoint1:cxpoint2] \\\n","                = ind2[cxpoint1:cxpoint2], ind1[cxpoint1:cxpoint2]\n","#             print('ind1 after two-point crossover:', ind1)\n","#             print('ind2 after two-point crossover:', ind2)\n","        # Uniform crossover\n","        elif selectCxType == 2:\n","#             print('ind1 before uniform crossover:', ind1)\n","#             print('ind2 before uniform crossover:', ind2)\n","            for i in range(size):\n","                if random.random() < self.cross_rate:\n","                    ind1[i], ind2[i] = ind2[i], ind1[i]\n","#             print('ind1 after uniform crossover:', ind1)\n","#             print('ind2 after uniform crossover:', ind2)\n","\n","        # Crossover for architecture chromosomes\n","        # One-cut point crossover from the Global MaxPooling layer\n","        cxpoint1 = ind1.index('global_maxpooling_layer')\n","        cxpoint2 = ind2.index('global_maxpooling_layer')\n","        ind1[cxpoint1:], ind2[cxpoint2:] = ind2[cxpoint2:], ind1[cxpoint1:]\n","\n","        max_drop_layer = max(ind1.count('dropout_layer'), ind2.count('dropout_layer'))\n","        if max_drop_layer > self.max_dropout_idx:\n","            idx = self.max_dropout_idx\n","            self.max_dropout_idx = max_drop_layer\n","\n","            while idx < self.max_dropout_idx:\n","                idx += 1\n","                addDropoutLayer(idx, self.toolbox, self.toolboxes, self.defaultVal, self.layerparameters)\n","\n","                for ind in pop + offspring:\n","                    ind.insert(size, random.uniform(0, 1))\n","                size += 1\n","\n","                self.write_result()\n","\n","        return ind1, ind2\n","\n","    def runGA(self, lastPop=[], lastFitnesses=[]):\n","        creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n","        creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n","\n","        self.toolbox.register(\"individual\", tools.initCycle, creator.Individual,\n","                              self.toolboxes, n=1)\n","        self.toolbox.register(\"population\", tools.initRepeat, list, self.toolbox.individual)\n","        self.toolbox.register(\"evaluate\", self.fitnessCalc)\n","        self.toolbox.register(\"mate\", self.cxTwoPoint)\n","        self.toolbox.register(\"mutate\", self.mutHyperparam, indpb=self.mut_rate)\n","        self.toolbox.register(\"select\", tools.selBest)\n","\n","        pop = self.toolbox.population(n=self.n_pop)\n","\n","        idx = 0\n","        for ind in pop:\n","            if lastPop:\n","                ind[:] = lastPop[idx]\n","            ind.extend(self.path_ind[idx])\n","            idx += 1\n","        \n","        if lastFitnesses:\n","            # Fitnesses from previous population\n","            fitnesses = lastFitnesses\n","        else:\n","            # Evaluate the entire population\n","            fitnesses = list(map(self.toolbox.evaluate, pop))\n","\n","        for ind, fit in zip(pop, fitnesses):\n","            ind.fitness.values = fit\n","\n","        self.write_result()\n","        \n","        g = 0\n","        increment = 0.01\n","        avgDistance = 1\n","        threshold = 0.5\n","        minRate = 0.01\n","        maxRate = 1.0\n","        \n","        while g < self.n_gen:\n","            then = time.time()\n","            g = g + 1\n","            print('{} {}'.format(datetime.datetime.now(), \"-- Generation %i --\" % g))\n","            \n","            if g > 1:\n","                # Adaptive crossover and mutation rates\n","                print('Crossover rate before adaptive scheme=', self.cross_rate)\n","                print('Mutation rate before adaptive scheme=', self.mut_rate)   \n","                \n","                if avgDistance > threshold:\n","                    self.mut_rate -= increment\n","                    self.cross_rate -= increment\n","                else:\n","                    self.mut_rate += increment\n","                    self.cross_rate += increment\n","                    \n","                if self.mut_rate > maxRate:\n","                    self.mut_rate = maxRate\n","                elif self.mut_rate < minRate:\n","                    self.mut_rate = minRate\n","\n","                if self.cross_rate > maxRate:\n","                    self.cross_rate = maxRate\n","                elif self.cross_rate < minRate:\n","                    self.cross_rate = minRate\n","                \n","                print('Crossover rate after adaptive scheme=', self.cross_rate)\n","                print('Mutation rate after adaptive scheme=', self.mut_rate)\n","            \n","            # Select the next generation individuals\n","            offspring = self.toolbox.select(pop, len(pop))\n","            # Clone the selected individuals\n","            offspring = list(map(self.toolbox.clone, offspring))\n","\n","            # Apply crossover and mutation on the offspring\n","            for child1, child2 in zip(offspring[::2], offspring[1::2]):\n","                if random.random() < self.cross_rate:\n","                    self.toolbox.mate(child1, child2, pop, offspring)\n","                    del child1.fitness.values\n","                    del child2.fitness.values\n","\n","            for mutant in offspring:\n","                if random.random() < self.mut_rate:\n","                    self.toolbox.mutate(mutant)\n","                    del mutant.fitness.values\n","\n","            # Evaluate the individuals with an invalid fitness\n","            self.invalid_fitness_calc(offspring)\n","\n","            pop[:] = self.toolbox.select(pop + offspring, self.n_pop)\n","\n","            # Gather all the fitnesses in one list and print the stats\n","            fits = [ind.fitness.values[0] for ind in pop]\n","\n","            length = len(pop)\n","            mean, std = self.std_calc(fits, length)\n","            avgDistance = self.distance_calc(pop)\n","            best = max(pop, key=attrgetter(\"fitness\"))\n","            print('{} {}'.format(datetime.datetime.now(), \"  Min %s\" % min(fits)))\n","            print('{} {}'.format(datetime.datetime.now(), \"  Max %s\" % max(fits)))\n","            print('{} {}'.format(datetime.datetime.now(), \"  Avg %s\" % mean))\n","            print('{} {}'.format(datetime.datetime.now(), \"  Std %s\" % std))\n","            print('{} {}'.format(datetime.datetime.now(), \"  AvgDistance %s\" % avgDistance))\n","            print('{} {}'.format(datetime.datetime.now(), best))\n","\n","            now = time.time()\n","            diff = now - then\n","\n","            # save testing data\n","            f = open(self.resultsPath + self.testing_name + \".csv\", 'a')\n","            text = \"{0},{1},{2},{3},{4},{5},{6},{7},{8}\".format(g,min(fits), max(fits), mean, std, avgDistance, diff, self.cross_rate, self.mut_rate)\n","            for param in best:\n","                text += \",{0}\".format(param)\n","            text += \"\\n\"\n","            f.write(text)\n","            f.close()\n","\n","            # save last population data\n","            f = open(self.resultsPath + self.testing_name + \"lastpop.csv\", 'a')\n","            for ind in pop:\n","                text = \"{0},{1}\".format(g,ind.fitness.values[0])\n","                for param in ind:\n","                    text += \",{0}\".format(param)\n","                text += \"\\n\"                 \n","                f.write(text)\n","\n","            f.close()            "],"metadata":{"id":"-mZKDHFYDSJD","executionInfo":{"status":"ok","timestamp":1674150768788,"user_tz":-330,"elapsed":623,"user":{"displayName":"ABDUL HAQUE","userId":"03599932539934700066"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["## perameters"],"metadata":{"id":"u4RFunCuEMXB"}},{"cell_type":"code","source":["# crossover rate is the probability with which two individuals\n","cross_rate = 0.8\n","\n","# mutation rate is the probability for mutating an individual\n","mut_rate = 0.2\n","\n","# number of population\n","n_pop = 30\n","\n","# number of generation\n","n_gen = 100"],"metadata":{"id":"MeXJt372DkCV","executionInfo":{"status":"ok","timestamp":1674150776712,"user_tz":-330,"elapsed":623,"user":{"displayName":"ABDUL HAQUE","userId":"03599932539934700066"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# !unzip /content/drive/MyDrive/test_train_val.zip -d /content/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zuSnTulmgLjF","executionInfo":{"status":"ok","timestamp":1672915110284,"user_tz":-330,"elapsed":21311,"user":{"displayName":"ABDUL HAQUE","userId":"03599932539934700066"}},"outputId":"a0c55f8b-c22f-44aa-c195-8da0ba0d316f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  /content/drive/MyDrive/test_train_val.zip\n","  inflating: /content/test_train_val/test_meta.csv  \n","  inflating: /content/test_train_val/test_signal.csv  \n","  inflating: /content/test_train_val/train_meta.csv  \n","  inflating: /content/test_train_val/train_signal.csv  \n","  inflating: /content/test_train_val/valid_meta.csv  \n","  inflating: /content/test_train_val/valid_signal.csv  \n"]}]},{"cell_type":"markdown","source":["## paths"],"metadata":{"id":"7Mp4ncg8fW89"}},{"cell_type":"code","source":["import os \n","# path\n","\n","training_path = 'train_signal.csv'\n","trial_path = 'test_signal.csv'\n","population_path = 'NewPop.csv'\n","root_path = '/content/drive/MyDrive/'\n","datasetPath = root_path \n","resultsPath = root_path \n","archPath = root_path \n","testing_name = \"GA-CNN with Adaptive Balance CRMR\"\n","glovePath = [root_path + '/Glove/glove.6B.50d.txt',\n","                 root_path + '/Glove/glove.6B.100d.txt',\n","                 root_path + '/Glove/glove.6B.200d.txt',\n","                 root_path + '/Glove/glove.6B.300d.txt']"],"metadata":{"id":"XLea3GeHfVS5","executionInfo":{"status":"ok","timestamp":1674151248080,"user_tz":-330,"elapsed":1095,"user":{"displayName":"ABDUL HAQUE","userId":"03599932539934700066"}}},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":["## main program"],"metadata":{"id":"w0hb7y_DEa2S"}},{"cell_type":"code","source":["import random\n","from sklearn.model_selection import StratifiedKFold\n","from deap import base\n","import warnings; warnings.simplefilter('ignore')\n","\n","if __name__ == '__main__':\n","    globalparameters = []\n","    globalparameters.append((\"epochs\", random.randint, 1, 100))\n","    globalparameters.append((\"batch_size\", random.randint, 32, 256))\n","\n","    globalparameters.append((\"optimizer\", random.choice, ['sgd', 'rmsprop', 'adagrad', 'adadelta', 'adam',\n","                                                          'adamax', 'nadam']))\n","    globalparameters.append((\"learning_rate\", random.uniform, 1e-4, 1e-2))\n","    globalparameters.append((\"momentum\", random.uniform, 0, 1))\n","    globalparameters.append((\"output_init_mode\", random.choice,\n","                             ['zeros',\n","                              'ones',\n","                              'uniform',\n","                              'normal',\n","                              'glorot_normal',\n","                              'glorot_uniform',\n","                              'he_normal',\n","                              'he_uniform',\n","                              'lecun_normal',\n","                              'lecun_uniform']))\n","    globalparameters.append((\"output_dim\", random.choice, [50, 100, 200, 300]))\n","\n","    layerparameters = {}\n","    layerparameters[\"num_filters\"] = [random.randint, 32, 512]\n","    layerparameters[\"kernel_size\"] = [random.randint, 1, 5]\n","    layerparameters[\"conv_activation_func\"] = [random.choice,\n","                                               ['relu', 'softmax', 'elu', 'selu',\n","                                                'softplus', 'softsign', 'tanh',\n","                                                'sigmoid', 'hard_sigmoid', 'linear']]\n","    layerparameters[\"conv_init_mode\"] = [random.choice,\n","                                         ['zeros',\n","                                          'ones',\n","                                          'uniform',\n","                                          'normal',\n","                                          'glorot_normal',\n","                                          'glorot_uniform',\n","                                          'he_normal',\n","                                          'he_uniform',\n","                                          'lecun_normal',\n","                                          'lecun_uniform']]\n","    layerparameters[\"conv_weight_constraint\"] = [random.randint, 1, 5]\n","    layerparameters[\"neurons\"] = [random.randint, 1, 30]\n","    layerparameters[\"dense_activation_func\"] = [random.choice,\n","                                                ['relu', 'softmax', 'elu', 'selu',\n","                                                 'softplus', 'softsign', 'tanh',\n","                                                 'sigmoid', 'hard_sigmoid', 'linear']]\n","    layerparameters[\"dense_init_mode\"] = [random.choice,\n","                                          ['zeros',\n","                                           'ones',\n","                                           'uniform',\n","                                           'normal',\n","                                           'glorot_normal',\n","                                           'glorot_uniform',\n","                                           'he_normal',\n","                                           'he_uniform',\n","                                           'lecun_normal',\n","                                           'lecun_uniform']]\n","    layerparameters[\"dense_weight_constraint\"] = [random.randint, 1, 5]\n","    layerparameters[\"pool_size\"] = [random.randint, 2, 6]\n","    layerparameters[\"dropout_rate\"] = [random.uniform, 0, 1]\n","\n","    defaultVal = collections.OrderedDict([\n","        (\"epochs\", 10),\n","        (\"batch_size\", 32),\n","        (\"optimizer\", \"adam\"),\n","        (\"learning_rate\", 1e-4),\n","        (\"momentum\", 0.9),\n","        (\"output_init_mode\", \"glorot_uniform\"),\n","        (\"output_dim\", 100)]\n","    )\n","    \n","    # object class\n","    util = utility()\n","    toolbox = base.Toolbox()\n","    toolboxes = []\n","\n","    # Attribute generator\n","    for hyper in globalparameters:\n","        if len(hyper) == 3:\n","            toolbox.register(hyper[0], hyper[1], hyper[2])\n","        else:\n","            toolbox.register(hyper[0], hyper[1], hyper[2], hyper[3])\n","\n","    toolboxes.append(toolbox.epochs)\n","    toolboxes.append(toolbox.batch_size)\n","    toolboxes.append(toolbox.optimizer)\n","    toolboxes.append(toolbox.learning_rate)\n","    toolboxes.append(toolbox.momentum)\n","    toolboxes.append(toolbox.output_init_mode)\n","    toolboxes.append(toolbox.output_dim)\n","\n","    path_ind, max_conv_idx, max_maxpooling_idx, max_dense_idx, max_dropout_idx = generateFSM(n_pop, layerparameters,\n","                                                                                             toolbox, toolboxes,\n","                                                                                             defaultVal)\n","\n","#     # Read population data\n","#     dfPopulation = util.read_CSV(resultsPath + population_path)\n","\n","#     path_ind, fitnesses, max_conv_idx, max_maxpooling_idx, max_dense_idx, max_dropout_idx = openFSM(dfPopulation, layerparameters,\n","#                                                                                          toolbox, toolboxes, defaultVal)\n","#     dfPopulation = dfPopulation.drop(columns=[col for col in dfPopulation if col not in defaultVal])\n","\n","#     population = dfPopulation.loc[:, ~dfPopulation.columns.str.match('Unnamed')].values.tolist()\n","\n","    # Read data\n","    #dfTraining = util.read_CSV(train_signal.csv)\n","    \n","    # Read trial data\n","    # dfTrial = util.read_CSV(test_signal.csv)\n","\n","    # textsTraining, labelsTraining = util.get_text_label(dfTraining)\n","    # textsTrial, labelsTrial = util.get_text_label(dfTrial)\n","    textsTraining = train_signal\n","    labelsTraining = train_bclass\n","    textsTrial = valid_signal\n","    labelsTrial = valid_bclass\n","    \n","    cfold = {}\n","\n","    X_train, X_val, y_train, y_val = util.get_training_trial_data(\n","        textsTraining, labelsTraining, textsTrial, labelsTrial)\n","    cfold= {'X_train': X_train, 'X_val': X_val, 'y_train': y_train, 'y_val': y_val}\n","                  \n","    ga = GeneticAlgorithm(toolbox, toolboxes, cross_rate, mut_rate, n_pop, n_gen, resultsPath, testing_name,\n","                          cfold, globalparameters, layerparameters, defaultVal, path_ind, max_conv_idx, max_maxpooling_idx, max_dense_idx, max_dropout_idx)\n","    ga.runGA()\n","#     ga.runGA(population, fitnesses)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"zTgHdGxPEReq","executionInfo":{"status":"error","timestamp":1674151261212,"user_tz":-330,"elapsed":2740,"user":{"displayName":"ABDUL HAQUE","userId":"03599932539934700066"}},"outputId":"c8fd6ae4-8b6b-4280-8379-8bc802cd855f"},"execution_count":23,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-d1521f931657>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    129\u001b[0m     ga = GeneticAlgorithm(toolbox, toolboxes, cross_rate, mut_rate, n_pop, n_gen, resultsPath, testing_name,\n\u001b[1;32m    130\u001b[0m                           cfold, globalparameters, layerparameters, defaultVal, path_ind, max_conv_idx, max_maxpooling_idx, max_dense_idx, max_dropout_idx)\n\u001b[0;32m--> 131\u001b[0;31m     \u001b[0mga\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunGA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;31m#     ga.runGA(population, fitnesses)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-13-e197fb8e3250>\u001b[0m in \u001b[0;36mrunGA\u001b[0;34m(self, lastPop, lastFitnesses)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0;31m# Evaluate the entire population\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m             \u001b[0mfitnesses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfitnesses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-13-e197fb8e3250>\u001b[0m in \u001b[0;36mfitnessCalc\u001b[0;34m(self, individual)\u001b[0m\n\u001b[1;32m     47\u001b[0m                     \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mfc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFitnessCalculation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindividual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultVal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresultsPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mfc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindividual\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-12-c9d06120ddfc>\u001b[0m in \u001b[0;36mFitnessCalculation\u001b[0;34m(individual, cfold, defaultVal, resultsPath, testing_name)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindividual\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefaultVal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindividual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcrossfold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindiv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresultsPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-12-c9d06120ddfc>\u001b[0m in \u001b[0;36mcrossfold\u001b[0;34m(indiv, path, fold, resultsPath, testing_name)\u001b[0m\n\u001b[1;32m     39\u001b[0m     class_weight = {0: 0.25,\n\u001b[1;32m     40\u001b[0m                     1: 0.75}\n\u001b[0;32m---> 41\u001b[0;31m     model.fit(fold['X_train'], fold['y_train'], epochs=indiv['epochs'], verbose=False, \n\u001b[0m\u001b[1;32m     42\u001b[0m               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X_val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m               batch_size=indiv['batch_size'], callbacks=callbacks, class_weight=class_weight)\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    ValueError: Exception encountered when calling layer \"conv1d_6\" (type Conv1D).\n    \n    Negative dimension size caused by subtracting 5 from 4 for '{{node sequential_1/conv1d_6/Conv1D}} = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](sequential_1/conv1d_6/Conv1D/ExpandDims, sequential_1/conv1d_6/Conv1D/ExpandDims_1)' with input shapes: [?,352,1,4], [1,5,352,214].\n    \n    Call arguments received by layer \"conv1d_6\" (type Conv1D):\n      • inputs=tf.Tensor(shape=(None, 352, 4), dtype=float32)\n"]}]},{"cell_type":"code","source":["\n"],"metadata":{"id":"MsI1BF7zkzkm"},"execution_count":null,"outputs":[]}]}